{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-weather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cross-shoot",
   "metadata": {},
   "source": [
    "# Bayesian sampler\n",
    "\n",
    "gonna write this in python with pyro!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-event",
   "metadata": {},
   "source": [
    "# The Bayesian Sampler model is roughly:\n",
    "\n",
    "$$P_{BS}(A) \\sim Beta(\\beta + S(A), \\beta+F(A))$$\n",
    "\n",
    "Where $S(A)$ and $F(A)$ are the number of success and failures sampled.\n",
    "\n",
    "We can rewrite that:\n",
    "\n",
    "$$P_{BS}(A) \\sim Beta(\\beta + \\pi(A)N, \\beta+(1-\\pi(A))N)$$\n",
    "\n",
    "\n",
    "Where $\\pi(A)$ is the proportion of successes in the mental simulation with $N$ samples and is a function of the true underlying model probability, $p(A)$. It is distributed:\n",
    "\n",
    "$$\\pi(A) \\sim Beta(p(A)*N, (1-p(A))*N)$$\n",
    "\n",
    "To which we assign a uniform prior (or the multidimensional dirichlet equivalent):\n",
    "\n",
    "$$p(A) \\sim Beta(1,1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "objective-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "import torch as t\n",
    "import pyro\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import Importance, EmpiricalMarginal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import functools\n",
    "\n",
    "t.set_default_tensor_type(t.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "wrong-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## starting with just one P b/c I am struggling w/ python rustiness and filepaths\n",
    "from dfply import *\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "## just to get the skeleton of the final data format\n",
    "df_raw = pd.read_csv(\"osfstorage-archive/Experiment 2/PrEstExp_001_111218_115935.csv\")\n",
    "df = (df_raw >> \n",
    "      group_by(X.querytype) >> \n",
    "      summarize(estimate = X.estimate.mean()) >>\n",
    "      mutate(estimate = X.estimate/100.)\n",
    "     )\n",
    "     \n",
    "## data munging (for later)\n",
    "\n",
    "# conjdisj_trials = [\"AorB\",\"notAorB\",\"AornotB\",\"notAornotB\", \"AandB\", \"notAandB\", \"AandnotB\", \"notAandnotB\"]\n",
    "# simple_df = df[~df.querytype.isin(conjdisj_trials)]\n",
    "# conjdisj_df = df[df.querytype.isin(conjdisj_trials)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "considerable-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_funcs = dict({\n",
    "    \"AandB\": lambda theta: t.matmul(theta, t.tensor([1.,0.,0.,0.])) ,\n",
    "    \"AandnotB\": lambda theta: t.matmul(theta, t.tensor([0.,1.,0.,0.])),\n",
    "    \"notAandB\": lambda theta: t.matmul(theta, t.tensor([0.,0.,1.,0.])),\n",
    "    \"notAandnotB\": lambda theta: t.matmul(theta, t.tensor([0.,0.,0.,1.])),\n",
    "    \"A\":lambda theta: t.matmul(theta, t.tensor([1.,1.,0.,0.])),\n",
    "    \"B\":lambda theta: t.matmul(theta, t.tensor([1.,0.,1.,0.])),\n",
    "    \"notA\":lambda theta: t.matmul(theta, t.tensor([0.,0.,1.,1.])),\n",
    "    \"notB\":lambda theta: t.matmul(theta, t.tensor([0.,1.,0.,1.])),\n",
    "    \"AorB\":lambda theta: t.matmul(theta, t.tensor([1.,1.,1.,0.])),\n",
    "    \"AornotB\":lambda theta: t.matmul(theta, t.tensor([1.,1.,0.,1.])),\n",
    "    \"notAorB\":lambda theta: t.matmul(theta, t.tensor([0.,1.,1.,1.])),\n",
    "    \"notAornotB\":lambda theta: t.matmul(theta, t.tensor([0.,1.,0.,1.])),\n",
    "    \n",
    "    \"AgB\": lambda theta: t.div( t.matmul(theta, t.tensor([1.,0.,0.,0.])), t.matmul(theta, t.tensor([1.,0.,1.,0.])) ),\n",
    "    \"notAgB\": lambda theta: t.div( t.matmul(theta, t.tensor([0.,0.,1.,0.])), t.matmul(theta, t.tensor([1.,0.,1.,0.])) ),\n",
    "    \"AgnotB\": lambda theta: t.div( t.matmul(theta, t.tensor([0.,1.,0.,0.])), t.matmul(theta, t.tensor([0.,1.,0.,1.])) ),\n",
    "    \"notAgnotB\": lambda theta: t.div( t.matmul(theta, t.tensor([0.,0.,0.,1.])), t.matmul(theta, t.tensor([0.,1.,0.,1.])) ),\n",
    "    \"BgA\": lambda theta: t.div( t.matmul(theta, t.tensor([1.,0.,0.,0.])), t.matmul(theta, t.tensor([1.,1.,0.,0.])) ),\n",
    "    \"notBgA\": lambda theta: t.div( t.matmul(theta, t.tensor([0.,1.,0.,0.])), t.matmul(theta, t.tensor([1.,1.,0.,0.])) ),\n",
    "    \"BgnotA\": lambda theta: t.div( t.matmul(theta, t.tensor([0.,0.,1.,0.])), t.matmul(theta, t.tensor([0.,0.,1.,1.])) ),\n",
    "    \"notBgnotA\": lambda theta: t.div( t.matmul(theta, t.tensor([0.,0.,0.,1.])), t.matmul(theta, t.tensor([0.,0.,1.,1.])) )\n",
    "})\n",
    "\n",
    "\n",
    "def dm_probs(trial_data, theta, n_obs):\n",
    "    ## compute implied subj. probability from latent theta and trial type\n",
    "    ## this is a vectorized solution: https://bit.ly/2P6mMcD\n",
    "    p = t.tensor([])\n",
    "    for i in range(0, n_obs):\n",
    "        temp = trial_func[trial_data[i]](theta)\n",
    "        p = t.cat( (p, t.tensor([temp])), 0)\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "id": "spectacular-species",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>querytype</th>\n",
       "      <th>block</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>AandB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>AandnotB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>AgB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>AgnotB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID querytype  block  response\n",
       "0   0         A      0  0.750657\n",
       "1   0     AandB      0  0.182357\n",
       "2   0  AandnotB      0  0.659741\n",
       "3   0       AgB      0  0.759823\n",
       "4   0    AgnotB      0  0.730055"
      ]
     },
     "execution_count": 1057,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim_sampling(p, beta, N, k):\n",
    "    p_bs = p * N / (N + 2.*beta) + beta/(N + 2.*beta)\n",
    "    return dist.Beta(p_bs*k, (1-p_bs)*k).sample()\n",
    "\n",
    "n_participants = 4\n",
    "n_blocks = 3\n",
    "\n",
    "trial_types = list(df.querytype)\n",
    "\n",
    "n_trial_types = len(trial_types)\n",
    "\n",
    "trials = trial_types*n_blocks\n",
    "blocks = list(np.repeat(np.array(list(range(0, n_blocks))), n_trial_types))\n",
    "\n",
    "all_participants = list(np.repeat(np.array(list(range(0, n_participants))), n_trial_types*n_blocks))\n",
    "all_trials = trials*n_participants\n",
    "all_blocks = blocks*n_participants\n",
    "all_responses = t.ones(0)\n",
    "\n",
    "all_thetas = []\n",
    "\n",
    "for i in range(0, n_participants):\n",
    "    theta = dist.Dirichlet(t.ones(4)).sample()\n",
    "\n",
    "    probs = dm_probs(trials, theta, len(trials))\n",
    "    responses = sim_sampling(probs, 1, 10, 100)\n",
    "    \n",
    "    all_thetas.append(theta)\n",
    "    all_responses = t.cat((all_responses, responses))\n",
    "\n",
    "# print(len(all_participants))\n",
    "# print(len(all_trials))\n",
    "# print(len(all_blocks))\n",
    "# print(len(all_responses))\n",
    "# print(len(all_thetas))\n",
    "\n",
    "\n",
    "sim_data = pd.DataFrame(\n",
    "    data = {\n",
    "        \"ID\": all_participants,\n",
    "        \"querytype\": all_trials, \n",
    "        \"block\": all_blocks,\n",
    "        \"response\": all_responses\n",
    "    }\n",
    ")\n",
    "\n",
    "sim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "informative-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulated data\n",
    "\n",
    "# for each id\n",
    "# # for each trial type\n",
    "# # # for each block\n",
    "\n",
    "# object[id][trial_type][block]\n",
    "# {\"0\": {\"AandB\": {\"0\": .35, }, ... }, ... }\n",
    "\n",
    "participant_keys = list(range(0, n_participants))\n",
    "trial_keys = set(list(sim_data.querytype))\n",
    "block_keys = list(range(0, n_blocks))\n",
    "\n",
    "# data_dict = {key: {key: {key: [] for key in block_keys} for key in participant_keys} for key in trial_keys}\n",
    "data_dict = {key: {key:[] for key in trial_keys} for key in participant_keys}\n",
    "# data_dict[\"A\"]\n",
    "\n",
    "# for each participant (they each have a theta)\n",
    "\n",
    "# grab their data\n",
    "\n",
    "# for each trial type\n",
    "\n",
    "# for each block\n",
    "\n",
    "# predict their probability\n",
    "\n",
    "# observe their responses in all blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "id": "athletic-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df_test = sim_data\n",
    "\n",
    "# need to change things around, feed in data separately for each trial type maybe?\n",
    "def sort_trials(trial_data, observations):\n",
    "    output = dict()\n",
    "    for key in set(trial_data):\n",
    "        output[key] = t.ones(0)\n",
    "        \n",
    "    for i in range(0, len(trial_data)):\n",
    "        output[trial_data[i]] = t.cat( (output[trial_data[i]], t.tensor([observations[i]])) )\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def sort_trials2(trial_data, block_data, participant_data, observations):\n",
    "    output = dict()\n",
    "    for key in set(trial_data):\n",
    "        output[key] = t.ones(0)\n",
    "        \n",
    "    for i in range(0, len(trial_data)):\n",
    "        output[trial_data[i]] = t.cat( (output[trial_data[i]], t.tensor([observations[i]])) )\n",
    "        \n",
    "    return output\n",
    "\n",
    "test_data = sort_trials(sim_data.querytype, sim_data.response)\n",
    "test_info = {\"n_Ps\":n_participants, \"n_blocks\":n_blocks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsampler_multi2(data, info):\n",
    "\n",
    "    n_obs = len(data[\"A\"])\n",
    "    n_total_obs = len(data.keys())*n_obs\n",
    "    n_Ps = info[\"n_Ps\"]\n",
    "    n_blocks = info[\"n_blocks\"]\n",
    "\n",
    "    # population level parameters/priors\n",
    "    beta = pyro.sample(\"beta\", dist.HalfCauchy(.25))\n",
    "    N = pyro.sample(\"N\", dist.HalfCauchy(5))\n",
    "    k = pyro.sample(\"k\", dist.HalfCauchy(5)) ## noise, all causes\n",
    "\n",
    "    # need a theta per person/querytype (yes?)\n",
    "    thetas = [pyro.sample(\"theta_{}\".format(j), dist.Dirichlet(t.ones(4))) for j in range(0,n_Ps)]\n",
    "    for subj in range(0, info[\"n_Ps\"]):\n",
    "        theta = theta[subj]\n",
    "        s_trials = \n",
    "\n",
    "        for trial in data.keys():\n",
    "            # ok so this is broken, result is the wrong size \n",
    "    #         f = t.vmap(trial_func[trial]) # maybe this isn't working?\n",
    "            f = trial_funcs[trial]\n",
    "            pi = f(theta).repeat(n_blocks) # now this is the wrong dim, should be n_blocks\n",
    "            p_bs = pi * N / (N + 2.*beta) + beta/(N + 2.*beta) # this is the wrong dim \n",
    "\n",
    "            yhat = pyro.sample(\"yhat_{}\".format(trial), dist.Beta(p_bs*k, (1.-p_bs)*k), obs=data[trial]) # ???\n",
    "    #         yhat = pyro.sample(\"yhat_{}\".format(trial), dist.Beta(p_bs*k, (1.-p_bs)*k)) # ???\n",
    "    \n",
    "    return p_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "naughty-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsampler(data, info):\n",
    "\n",
    "    n_obs = len(data[\"A\"])\n",
    "    n_total_obs = len(data.keys())*n_obs\n",
    "    n_Ps = info[\"n_Ps\"]\n",
    "    n_blocks = info[\"n_blocks\"]\n",
    "\n",
    "    # population level parameters/priors\n",
    "    beta = pyro.sample(\"beta\", dist.HalfCauchy(.25))\n",
    "    N = pyro.sample(\"N\", dist.HalfCauchy(5))\n",
    "    k = pyro.sample(\"k\", dist.HalfCauchy(5)) ## noise, all causes\n",
    "\n",
    "    # need a theta per person/querytype (yes?)    \n",
    "    theta = pyro.sample(\"theta\", dist.Dirichlet(t.ones(n_Ps, 4)))\n",
    "\n",
    "    for trial in data.keys():\n",
    "        # ok so this is broken, result is the wrong size \n",
    "        f = t.vmap(trial_func[trial]) # I think I could actually map the whole thing and get rid of this outer for loop too\n",
    "        pi = f(theta) # this is the right dim\n",
    "        p_bs = pi.repeat(n_blocks) * N / (N + 2.*beta) + beta/(N + 2.*beta) # this is the wrong dim   \n",
    "        pyro.sample(\"yhat_{}\".format(trial), dist.Beta(p_bs*k, (1.-p_bs)*k), obs=data[trial]) # ???\n",
    "#         yhat = pyro.sample(\"yhat_{}\".format(trial), dist.Beta(p_bs*k, (1.-p_bs)*k)) # ???\n",
    "    \n",
    "    return p_bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "arbitrary-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/750 [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: torch.vmap is an experimental prototype that is subject to change and/or deletion. Please use at your own risk. There may be unexpected performance cliffs due to certain operators not being implemented. To see detailed performance warnings please use `torch._C._debug_only_display_vmap_fallback_warnings(True) before the call to `vmap`.\n",
      "Sample: 100%|██████████| 750/750 [06:33,  1.90it/s, step size=1.14e-01, acc. prob=0.951]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "      beta      0.73      0.90      0.46      0.03      1.51    147.61      1.02\n",
      "         N      4.06      4.76      2.61      0.07      8.60    151.32      1.02\n",
      "         k      4.54      0.13      4.54      4.33      4.76   1093.23      1.00\n",
      "theta[0,0]      0.23      0.02      0.23      0.19      0.27    621.16      1.00\n",
      "theta[0,1]      0.28      0.03      0.28      0.23      0.33    718.37      1.00\n",
      "theta[0,2]      0.21      0.02      0.21      0.17      0.24    620.99      1.00\n",
      "theta[0,3]      0.28      0.03      0.28      0.24      0.32    626.43      1.00\n",
      "theta[1,0]      0.22      0.02      0.22      0.18      0.26   1166.55      1.00\n",
      "theta[1,1]      0.29      0.03      0.29      0.25      0.34    493.88      1.00\n",
      "theta[1,2]      0.20      0.02      0.20      0.17      0.24    555.70      1.00\n",
      "theta[1,3]      0.28      0.03      0.28      0.24      0.32    389.25      1.01\n",
      "theta[2,0]      0.22      0.03      0.22      0.18      0.26    580.47      1.00\n",
      "theta[2,1]      0.27      0.03      0.27      0.23      0.33   1118.10      1.00\n",
      "theta[2,2]      0.21      0.02      0.21      0.17      0.25    600.09      1.00\n",
      "theta[2,3]      0.29      0.03      0.29      0.25      0.34    663.26      1.00\n",
      "theta[3,0]      0.23      0.02      0.23      0.19      0.27    524.94      1.00\n",
      "theta[3,1]      0.28      0.03      0.27      0.23      0.32    503.35      1.00\n",
      "theta[3,2]      0.22      0.02      0.22      0.17      0.25    667.12      1.00\n",
      "theta[3,3]      0.28      0.03      0.28      0.24      0.33    530.70      1.00\n",
      "theta[4,0]      0.23      0.03      0.23      0.19      0.27    628.12      1.00\n",
      "theta[4,1]      0.28      0.03      0.27      0.23      0.32    828.42      1.00\n",
      "theta[4,2]      0.21      0.03      0.21      0.17      0.25    785.10      1.00\n",
      "theta[4,3]      0.28      0.03      0.28      0.24      0.32    629.44      1.00\n",
      "theta[5,0]      0.22      0.02      0.22      0.19      0.26    428.66      1.00\n",
      "theta[5,1]      0.28      0.03      0.28      0.23      0.33    834.32      1.00\n",
      "theta[5,2]      0.21      0.03      0.21      0.16      0.25    656.33      1.00\n",
      "theta[5,3]      0.29      0.03      0.29      0.25      0.34    665.22      1.00\n",
      "theta[6,0]      0.23      0.02      0.23      0.19      0.26   1136.25      1.00\n",
      "theta[6,1]      0.29      0.03      0.29      0.24      0.33    610.71      1.00\n",
      "theta[6,2]      0.21      0.02      0.21      0.17      0.24    411.73      1.01\n",
      "theta[6,3]      0.28      0.03      0.28      0.24      0.32    515.77      1.01\n",
      "theta[7,0]      0.23      0.03      0.23      0.19      0.27    544.57      1.00\n",
      "theta[7,1]      0.28      0.03      0.28      0.24      0.33    500.30      1.00\n",
      "theta[7,2]      0.21      0.02      0.21      0.17      0.25    578.51      1.00\n",
      "theta[7,3]      0.27      0.03      0.27      0.23      0.32    475.59      1.00\n",
      "theta[8,0]      0.23      0.03      0.23      0.18      0.26    292.92      1.00\n",
      "theta[8,1]      0.28      0.03      0.28      0.23      0.33    702.36      1.00\n",
      "theta[8,2]      0.21      0.02      0.20      0.16      0.24    877.11      1.00\n",
      "theta[8,3]      0.29      0.03      0.29      0.24      0.33    386.69      1.01\n",
      "theta[9,0]      0.22      0.02      0.22      0.18      0.26    592.42      1.00\n",
      "theta[9,1]      0.28      0.03      0.28      0.24      0.33    969.08      1.00\n",
      "theta[9,2]      0.21      0.02      0.21      0.18      0.25    575.05      1.00\n",
      "theta[9,3]      0.29      0.03      0.29      0.25      0.34    876.80      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.mcmc import NUTS, MCMC\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "nuts_kernel = NUTS(bsampler, adapt_step_size=True)\n",
    "py_mcmc = MCMC(nuts_kernel, num_samples=500, warmup_steps=250)\n",
    "\n",
    "py_mcmc.run(test_data, test_info)\n",
    "py_mcmc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "compound-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1979, 0.0612, 0.4918, 0.2491])"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-springfield",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
