{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naughty-marble",
   "metadata": {},
   "source": [
    "# Bayesian sampler\n",
    "\n",
    "gonna write this in python with pyro!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-commander",
   "metadata": {},
   "source": [
    "The Bayesian Sampler model is roughly:\n",
    "\n",
    "$$P_{BS}(A) \\sim Beta(\\beta + S(A), \\beta+F(A))$$\n",
    "\n",
    "Where $S(A)$ and $F(A)$ are the number of success and failures sampled.\n",
    "\n",
    "We can rewrite that:\n",
    "\n",
    "$$P_{BS}(A) \\sim Beta(\\beta + \\pi(A)N, \\beta+(1-\\pi(A))N)$$\n",
    "\n",
    "\n",
    "Where $\\pi(A)$ is the proportion of successes in the mental simulation with $N$ samples and is a function of the true underlying model probability, $p(A)$. It is distributed:\n",
    "\n",
    "$$\\pi(A) \\sim Beta(p(A)*N, (1-p(A))*N)$$\n",
    "\n",
    "To which we assign a uniform prior (or the multidimensional dirichlet equivalent):\n",
    "\n",
    "$$p(A) \\sim Beta(1,1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "proud-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import Importance, EmpiricalMarginal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import functools\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-abraham",
   "metadata": {},
   "source": [
    "let's write down my thinking so far for the bayesian sampler and draw some samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "prescription-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsampler():\n",
    "    beta = pyro.sample(\"beta\", dist.HalfCauchy(1))\n",
    "    N = pyro.sample(\"N\", dist.HalfCauchy(5))\n",
    "    theta = pyro.sample(\"theta\", dist.Dirichlet(torch.ones(4)))\n",
    "    x = torch.tensor([1.,1.,0.,0.]) # just at test\n",
    "    p = torch.matmul(theta,x)\n",
    "    \n",
    "    pi = pyro.sample(\"pi\", dist.Beta(p*N, p*N))\n",
    "    y_hat = pyro.sample(\"y_hat\", dist.Beta(beta + pi*N, beta + (1-pi)*N))\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "vanilla-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(np.array([bsampler() for _ in range(2000)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-message",
   "metadata": {},
   "source": [
    "Holy COW! that was a lot easier than writing in Stan!\n",
    "\n",
    "Ok now let's pull in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "curious-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## starting with just one P b/c I am struggling w/ python rustiness and filepaths\n",
    "from dfply import *\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv(\"osfstorage-archive/Experiment 2/PrEstExp_001_111218_115935.csv\")\n",
    "\n",
    "df = (df_raw >> \n",
    "      group_by(X.querytype) >> \n",
    "      summarize(estimate = X.estimate.mean()) >>\n",
    "      mutate(estimate = X.estimate/100.)\n",
    "     )\n",
    "\n",
    "test_df = df[df.querytype.isin([\"A\",\"B\",\"AandB\",\"AandnotB\",\"notAandB\",\"notAandnotB\",\"notA\",\"notB\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "relevant-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = list(test_df[\"querytype\"])\n",
    "observations = torch.tensor(test_df[\"estimate\"].values)\n",
    "\n",
    "test_data = {\"trial\":trials, \"obs\":observations}\n",
    "\n",
    "trial_dict = dict({\n",
    "    \"AandB\": torch.tensor([1.,0.,0.,0.]),\n",
    "    \"AandnotB\": torch.tensor([0.,1.,0.,0.]),\n",
    "    \"notAandB\": torch.tensor([0.,0.,1.,0.]),\n",
    "    \"notAandnotB\": torch.tensor([0.,0.,0.,1.]),\n",
    "    \"A\":torch.tensor([1.,1.,0.,0.]),\n",
    "    \"B\":torch.tensor([1.,0.,1.,0.]),\n",
    "    \"notA\":torch.tensor([0.,0.,1.,1.]),\n",
    "    \"notB\":torch.tensor([0.,1.,0.,1.]),\n",
    "    \"AorB\":torch.tensor([1.,1.,1.,0.]),\n",
    "    \"AornotB\":torch.tensor([1.,1.,0.,1.]),\n",
    "    \"notAorB\":torch.tensor([0.,1.,1.,1.]),\n",
    "    \"notAornotB\":torch.tensor([0.,1.,0.,1.]),\n",
    "})\n",
    "\n",
    "## need to create a new dict for conditional probability trials\n",
    "    \n",
    "def bsampler(data):\n",
    "    # population level parameters/priors\n",
    "    beta = pyro.sample(\"beta\", dist.HalfCauchy(.25))\n",
    "    N = pyro.sample(\"N\", dist.HalfCauchy(5))\n",
    "    \n",
    "    # need a theta per person/querytype\n",
    "    theta = pyro.sample(\"theta\", dist.Dirichlet(torch.ones(4)))\n",
    "\n",
    "    # need pi and response per trial\n",
    "    for i in range(len(data[\"trial\"])):\n",
    "        \n",
    "        x = trial_dict[data[\"trial\"][i]]\n",
    "        p = torch.matmul(theta, x)\n",
    "        pi = pyro.sample(\"pi_{}\".format(i), dist.Beta(p*N, p*N))\n",
    "        pyro.sample(\"yhat_{}\".format(i), dist.Beta(beta + pi*N, beta + (1-pi)*N), obs=data[\"obs\"][i])\n",
    "\n",
    "# sns.histplot(np.array([bsampler(trial_dict[\"AorB\"]) for _ in range(1000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "retired-doctrine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/1500 [13:33, ?it/s]it/s, step size=2.93e-01, acc. prob=0.748]\n",
      "Warmup:   0%|          | 0/1500 [00:31, ?it/s]\n",
      "Sample: 100%|██████████| 1500/1500 [19:52,  1.26it/s, step size=2.40e-02, acc. prob=0.969]\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.mcmc import NUTS, MCMC\n",
    "\n",
    "# conditioned_model = pyro.condition(bsampler, data={\"y_hat\":observations[0]})\n",
    "\n",
    "nuts_kernel = NUTS(bsampler, adapt_step_size=True)\n",
    "py_mcmc = MCMC(nuts_kernel, num_samples=1_000, warmup_steps=500)\n",
    "\n",
    "py_mcmc.run(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "authentic-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "      beta      3.88      4.25      2.56      0.00     10.12     62.00      1.00\n",
      "         N     18.04     21.22      9.05      0.11     45.73     39.10      1.00\n",
      "  theta[0]      0.27      0.19      0.23      0.00      0.53    219.72      1.00\n",
      "  theta[1]      0.21      0.16      0.17      0.01      0.42    302.77      1.00\n",
      "  theta[2]      0.29      0.19      0.26      0.02      0.57    255.87      1.01\n",
      "  theta[3]      0.23      0.16      0.20      0.01      0.45    297.83      1.00\n",
      "      pi_0      0.59      0.21      0.60      0.34      1.00   1023.38      1.00\n",
      "      pi_1      0.50      0.25      0.51      0.00      0.86    377.56      1.00\n",
      "      pi_2      0.69      0.23      0.68      0.47      1.00    467.88      1.00\n",
      "      pi_3      0.55      0.20      0.55      0.29      1.00   1140.06      1.00\n",
      "      pi_4      0.56      0.21      0.55      0.32      1.00    276.01      1.01\n",
      "      pi_5      0.43      0.25      0.44      0.00      0.77    606.47      1.00\n",
      "      pi_6      0.63      0.25      0.63      0.31      1.00    475.82      1.00\n",
      "      pi_7      0.62      0.21      0.61      0.39      1.00    326.63      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "py_mcmc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-hawaiian",
   "metadata": {},
   "source": [
    "Welp it ran! Pretty slow considering so little data and effective samples is very poor for $\\beta$ and $N$, which I suppose is no surprise since they may not be identifiable. I'm not sure if there's anything I can do with better priors or reparameterizing that would help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-watershed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
