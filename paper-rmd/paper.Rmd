---
title: A template for the *arxiv* style
authors:
  - name: Derek Powell
    # thanks: Arizona State University
    department: School of Social and Behavioral Sciences
    affiliation: Arizona State University
    location: Phoenix, AZ
    email: dmpowell@asu.edu
abstract: |
  Enter the text of your abstract here.
keywords:
  - blah
  - blee
  - bloo
  - these are optional and can be removed
bibliography: references.bib
biblio-style: unsrt
output: 
  rticles::arxiv_article:
    keep_tex: true
---

```{r load_packages, include=FALSE}
library(tidyverse)
library(kableExtra)
```

# Introduction

Bayesian theories of cognition have had remarkable successes in explaining human reasoning and behavior across many domains (big cite). [The core of these theories is that people reason according to subjective mentally-represented degrees of belief, and they specify how they should be revised in light of evidence. It is somewhat embarrassing then that one area where these theories seem to fall down is in describing human "beliefs'' of the simple and everyday sort, such as beliefs like "it will rain tomorrow", “vaccines are safe,” or “this politician is trustworthy”.

Trouble starts as soon as we seek to measure beliefs. According to Bayesian theories of cognition and epistemology, the degree to which people believe in various propositions should reflect subjective mental probabilities. So asking people to express beliefs in terms of probability seems only natural. 

Unfortunately, people’s explicit probability judgments routinely violate the axioms of probability theory. For example, human probability judgments often exhibit the “conjunction fallacy”: people will often judge the conjunction of two events (e.g. “Tom Brady likes football and miniature horses”) as being more probable than one of the events in isolation (e.g. “Tom Brady likes miniature horses”), a plain and flagrant violation of probability theory (cite some examples). Other demonstrations of the incoherence of probability judgments include disjunction fallacies (e.g. XXX), “unpacking” effects (e.g. fox & tversky), and a variety of other effects illustrating the incoherence of human probability judgments [cite]. Altogether these findings have led many researchers to abandon the notion that credences are represented as probabilities.

Recently however, two groups of researchers have proposed theories of human probability judgments that account for biases and apparent incoherence in these judgments while maintaining that mental credences are fundamentally probabilistic [@costello.watts2014; @zhu.etal2020]. Both of these theories build on the increasingly popular notion that a variety of human reasoning tasks are accomplished by drawing a limited number of samples from probabilistic mental models [see also @chater.etal2020; @dasgupta.etal2017]. 

## Two probabilistic theories of probability judgment

Costello & Watts [-@costello.watts2014; -@costello.watts2016; -@costello.watts2018] proposed a theory of probability judgment they call the “Probability Theory plus Noise” theory (PT+N). In the PT+N model, mental “samples” are drawn from a probabilistic mental model of events and are then “read” with noise, so that some positive examples will be read as negative and some negative read as positive. This results in probability judgments that reflect probabilistic credences perturbed by noise. Under the simplest form of the PT+N model, the expected value of probability judgments is:

$$E[\hat{P}_{PT+N}(A)] = (1-2d)P(A) + d $$

where *d* represents the probability with which samples will be misread, or the amount of noise in the judgment process (where by assumption a maximum of 50% of samples can be misread, so that d is a number in the range [0, .50]). The PT+N theory provides a unified accounts for a wide variety of biases in probability judgment that were previously attributed to different types of heuristics [@costello.watts2014; @costello.watts2016; @costello.watts2017; @costello.watts2018].

