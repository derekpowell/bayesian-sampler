@article{anderson1991,
  title = {The Adaptive Nature of Human Categorization.},
  author = {Anderson, John R.},
  year = {1991},
  volume = {98},
  pages = {409--429},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.98.3.409},
  file = {/Users/dmpowell/Zotero/storage/KEGINXGG/Anderson - 1991 - The adaptive nature of human categorization..pdf},
  journal = {Psychological Review},
  language = {en},
  number = {3}
}

@article{battaglia.etal2013,
  title = {Simulation as an Engine of Physical Scene Understanding},
  author = {Battaglia, Peter W. and Hamrick, Jessica B. and Tenenbaum, Joshua B.},
  year = {2013},
  month = nov,
  volume = {110},
  pages = {18327--18332},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1306572110},
  abstract = {In a glance, we can perceive whether a stack of dishes will topple, a branch will support a child's weight, a grocery bag is poorly packed and liable to tear or crush its contents, or a tool is firmly attached to a table or free to be lifted. Such rapid physical inferences are central to how people interact with the world and with each other, yet their computational underpinnings are poorly understood. We propose a model based on an ``intuitive physics engine,'' a cognitive mechanism similar to computer engines that simulate rich physics in video games and graphics, but that uses approximate, probabilistic simulations to make robust and fast inferences in complex natural scenes where crucial information is unobserved. This single model fits data from five distinct psychophysical tasks, captures several illusions and biases, and explains core aspects of human mental models and common-sense reasoning that are instrumental to how humans understand their everyday world.},
  chapter = {Biological Sciences},
  copyright = {\textcopyright{}  . Freely available online through the PNAS open access option.},
  file = {/Users/dmpowell/Zotero/storage/ILTH8F7H/Battaglia et al. - 2013 - Simulation as an engine of physical scene understa.pdf;/Users/dmpowell/Zotero/storage/MJS3HUGG/18327.html},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {45},
  pmid = {24145417}
}

@article{busemeyer.etal2011,
  title = {A {{Quantum Theoretical Explanation}} for {{Probability Judgment Errors}}},
  author = {Busemeyer, Jerome and Pothos, Emmanuel and Franco, Riccardo and Trueblood, Jennifer},
  year = {2011},
  month = apr,
  volume = {118},
  pages = {193--218},
  doi = {10.1037/a0022542},
  abstract = {A quantum probability model is introduced and used to explain human probability judgment errors including the conjunction and disjunction fallacies, averaging effects, unpacking effects, and order effects on inference. On the one hand, quantum theory is similar to other categorization and memory models of cognition in that it relies on vector spaces defined by features and similarities between vectors to determine probability judgments. On the other hand, quantum probability theory is a generalization of Bayesian probability theory because it is based on a set of (von Neumann) axioms that relax some of the classic (Kolmogorov) axioms. The quantum model is compared and contrasted with other competing explanations for these judgment errors, including the anchoring and adjustment model for probability judgments. In the quantum model, a new fundamental concept in cognition is advanced--the compatibility versus incompatibility of questions and the effect this can have on the sequential order of judgments. We conclude that quantum information-processing principles provide a viable and promising new way to understand human judgment and reasoning.},
  file = {/Users/dmpowell/Documents/Papers/busemeyer et al-2011-a quantum theoretical explanation for probability judgment errors.pdf},
  journal = {Psychological review}
}

@article{busemeyer.wang2000,
  title = {Model {{Comparisons}} and {{Model Selections Based}} on {{Generalization Criterion Methodology}}},
  author = {Busemeyer, Jerome R and Wang, Yi-Min},
  year = {2000},
  month = mar,
  volume = {44},
  pages = {171--189},
  issn = {00222496},
  doi = {10.1006/jmps.1999.1282},
  file = {/Users/dmpowell/Zotero/storage/8WYN3QMJ/Busemeyer and Wang - 2000 - Model Comparisons and Model Selections Based on Ge.pdf},
  journal = {Journal of Mathematical Psychology},
  language = {en},
  number = {1}
}

@article{chater.etal2020,
  title = {Probabilistic {{Biases Meet}} the {{Bayesian Brain}}},
  author = {Chater, Nick and Zhu, Jian-Qiao and Spicer, Jake and Sundh, Joakim and {Le{\'o}n-Villagr{\'a}}, Pablo and Sanborn, Adam},
  year = {2020},
  month = oct,
  volume = {29},
  pages = {506--512},
  publisher = {{SAGE Publications Inc}},
  issn = {0963-7214},
  doi = {10.1177/0963721420954801},
  abstract = {In Bayesian cognitive science, the mind is seen as a spectacular probabilistic-inference machine. But judgment and decision-making (JDM) researchers have spent half a century uncovering how dramatically and systematically people depart from rational norms. In this article, we outline recent research that opens up the possibility of an unexpected reconciliation. The key hypothesis is that the brain neither represents nor calculates with probabilities but approximates probabilistic calculations by drawing samples from memory or mental simulation. Sampling models diverge from perfect probabilistic calculations in ways that capture many classic JDM findings, which offers the hope of an integrated explanation of classic heuristics and biases, including availability, representativeness, and anchoring and adjustment.},
  file = {/Users/dmpowell/Documents/Papers/chater et al-2020-probabilistic biases meet the bayesian brain.pdf},
  journal = {Current Directions in Psychological Science},
  number = {5}
}

@article{cook.lewandowsky2016,
  title = {Rational {{Irrationality}}: {{Modeling Climate Change Belief Polarization Using Bayesian Networks}}},
  shorttitle = {Rational {{Irrationality}}},
  author = {Cook, John and Lewandowsky, Stephan},
  year = {2016},
  month = jan,
  volume = {8},
  pages = {160--179},
  issn = {17568757},
  doi = {10.1111/tops.12186},
  abstract = {Belief polarization is said to occur when two people respond to the same evidence by updating their beliefs in opposite directions. This response is considered to be ``irrational'' because it involves contrary updating, a form of belief updating that appears to violate normatively optimal responding, as for example dictated by Bayes' theorem. In light of much evidence that people are capable of normatively optimal behavior, belief polarization presents a puzzling exception. We show that Bayesian networks, or Bayes nets, can simulate rational belief updating. When fit to experimental data, Bayes nets can help identify the factors that contribute to polarization. We present a study into belief updating concerning the reality of climate change in response to information about the scientific consensus on anthropogenic global warming (AGW). The study used representative samples of Australian and U.S. participants. Among Australians, consensus information partially neutralized the influence of worldview, with free-market supporters showing a greater increase in acceptance of human-caused global warming relative to free-market opponents. In contrast, while consensus information overall had a positive effect on perceived consensus among U.S. participants, there was a reduction in perceived consensus and acceptance of humancaused global warming for strong supporters of unregulated free markets. Fitting a Bayes net model to the data indicated that under a Bayesian framework, free-market support is a significant driver of beliefs about climate change and trust in climate scientists. Further, active distrust of climate scientists among a small number of U.S. conservatives drives contrary updating in response to consensus information among this particular group.},
  file = {/Users/dmpowell/Documents/Papers/Cook and Lewandowsky - 2016 - Rational Irrationality Modeling Climate Change Be.pdf},
  journal = {Topics in Cognitive Science},
  language = {en},
  number = {1}
}

@article{costello.watts2014,
  title = {Surprisingly Rational: {{Probability}} Theory plus Noise Explains Biases in Judgment.},
  shorttitle = {Surprisingly Rational},
  author = {Costello, Fintan and Watts, Paul},
  year = {2014},
  volume = {121},
  pages = {463--480},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0037010},
  abstract = {The systematic biases seen in people's probability judgments are typically taken as evidence that people do not use the rules of probability theory when reasoning about probability but instead use heuristics, which sometimes yield reasonable judgments and sometimes yield systematic biases. This view has had a major impact in economics, law, medicine, and other fields; indeed, the idea that people cannot reason with probabilities has become a truism. We present a simple alternative to this view, where people reason about probability according to probability theory but are subject to random variation or noise in the reasoning process. In this account the effect of noise is canceled for some probabilistic expressions. Analyzing data from 2 experiments, we find that, for these expressions, people's probability judgments are strikingly close to those required by probability theory. For other expressions, this account produces systematic deviations in probability estimates. These deviations explain 4 reliable biases in human probabilistic reasoning (conservatism, subadditivity, conjunction, and disjunction fallacies). These results suggest that people's probability judgments embody the rules of probability theory and that biases in those judgments are due to the effects of random noise.},
  file = {/Users/dmpowell/Documents/Papers/Costello and Watts - 2014 - Surprisingly rational Probability theory plus noi.pdf},
  journal = {Psychological Review},
  language = {en},
  number = {3}
}

@article{costello.watts2016,
  title = {People's Conditional Probability Judgments Follow Probability Theory (plus Noise)},
  author = {Costello, Fintan and Watts, Paul},
  year = {2016},
  month = sep,
  volume = {89},
  pages = {106--133},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2016.06.006},
  abstract = {A common view in current psychology is that people estimate probabilities using various `heuristics' or rules of thumb that do not follow the normative rules of probability theory. We present a model where people estimate conditional probabilities such as P\dh AjB\TH{} (the probability of A given that B has occurred) by a process that follows standard frequentist probability theory but is subject to random noise. This model accounts for various results from previous studies of conditional probability judgment. This model predicts that people's conditional probability judgments will agree with a series of fundamental identities in probability theory whose form cancels the effect of noise, while deviating from probability theory in other expressions whose form does not allow such cancellation. Two experiments strongly confirm these predictions, with people's estimates on average agreeing with probability theory for the noise-cancelling identities, but deviating from probability theory (in just the way predicted by the model) for other identities. This new model subsumes an earlier model of unconditional or `direct' probability judgment which explains a number of systematic biases seen in direct probability judgment (Costello \& Watts, 2014). This model may thus provide a fully general account of the mechanisms by which people estimate probabilities.},
  file = {/Users/dmpowell/Documents/Papers/Costello and Watts - 2016 - People’s conditional probability judgments follow .pdf},
  journal = {Cognitive Psychology},
  language = {en}
}

@article{costello.watts2017,
  title = {Explaining {{High Conjunction Fallacy Rates}}: {{The Probability Theory Plus Noise Account}}},
  shorttitle = {Explaining {{High Conjunction Fallacy Rates}}},
  author = {Costello, Fintan and Watts, Paul},
  year = {2017},
  volume = {30},
  pages = {304--321},
  issn = {1099-0771},
  doi = {10.1002/bdm.1936},
  abstract = {The conjunction fallacy occurs when people judge the conjunctive probability P(A {$\wedge$} B) to be greater than a constituent probability P(A), contrary to the norms of probability theory. This fallacy is a reliable, consistent and systematic part of people's probability judgements, attested in many studies over at least 40 years. For some events, these fallacies occur very frequently in people's judgements (at rates of 80\% or more), while for other events, the fallacies are very rare (occurring at rates of 10\% or less). This wide range of fallacy rates presents a challenge for current theories of the conjunction fallacy. We show how this wide range of observed fallacy rates can be explained by a simple model where people reason according to probability theory but are subject to random noise in the reasoning process. Copyright \textcopyright{} 2016 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bdm.1936},
  file = {/Users/dmpowell/Documents/Papers/costello-watts-2017-explaining high conjunction fallacy rates.pdf;/Users/dmpowell/Zotero/storage/M55NM5GI/bdm.html},
  journal = {Journal of Behavioral Decision Making},
  keywords = {biases,conjunction fallacy,probability estimation,rationality},
  language = {en},
  number = {2}
}

@article{costello.watts2018,
  title = {Invariants in Probabilistic Reasoning},
  author = {Costello, Fintan and Watts, Paul},
  year = {2018},
  month = feb,
  volume = {100},
  pages = {1--16},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2017.11.003},
  abstract = {Recent research has identified three invariants or identities that appear to hold in people's probabilistic reasoning: the QQ identity, the addition law identity, and the Bayes rule identity (Costello and Watts, 2014, 2016a, Fisher and Wolfe, 2014, Wang and Busemeyer, 2013, Wang et al., 2014). Each of these identities represent specific agreement with the requirements of normative probability theory; strikingly, these identities seem to hold in people's judgements despite the presence of strong and systematic biases against the requirements of normative probability theory in those very same judgements. These results suggest that the systematic biases seen in people's probabilistic reasoning follow mathematical rules: for these particular identities, these rules cause an overall cancellation of biases and so produce agreement with normative requirements. We assess two competing mathematical models of probabilistic reasoning (the `probability theory plus noise' model and the `quantum probability' model) in terms of their ability to account for this pattern of systematic biases and invariant identities.},
  file = {/Users/dmpowell/Zotero/storage/LDW7AFFB/Costello and Watts - 2018 - Invariants in probabilistic reasoning.pdf},
  journal = {Cognitive Psychology},
  language = {en}
}

@article{dasgupta.etal2017,
  title = {Where Do Hypotheses Come From?},
  author = {Dasgupta, Ishita and Schulz, Eric and Gershman, Samuel J.},
  year = {2017},
  month = aug,
  volume = {96},
  pages = {1--25},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2017.05.001},
  abstract = {Why are human inferences sometimes remarkably close to the Bayesian ideal and other times systematically biased? In particular, why do humans make near-rational inferences in some natural domains where the candidate hypotheses are explicitly available, whereas tasks in similar domains requiring the self-generation of hypotheses produce systematic deviations from rational inference. We propose that these deviations arise from algorithmic processes approximating Bayes' rule. Specifically in our account, hypotheses are generated stochastically from a sampling process, such that the sampled hypotheses form a Monte Carlo approximation of the posterior. While this approximation will converge to the true posterior in the limit of infinite samples, we take a small number of samples as we expect that the number of samples humans take is limited. We show that this model recreates several well-documented experimental findings such as anchoring and adjustment, subadditivity, superadditivity, the crowd within as well as the self-generation effect, the weak evidence, and the dud alternative effects. We confirm the model's prediction that superadditivity and subadditivity can be induced within the same paradigm by manipulating the unpacking and typicality of hypotheses. We also partially confirm our model's prediction about the effect of time pressure and cognitive load on these effects.},
  file = {/Users/dmpowell/Documents/Papers/dasgupta et al-2017-where do hypotheses come from.pdf;/Users/dmpowell/Zotero/storage/NE32X76P/S0010028516302766.html},
  journal = {Cognitive Psychology},
  keywords = {Bayesian inference,Hypothesis generation,Monte Carlo methods},
  language = {en}
}

@article{fennell.baddeley2012,
  title = {Uncertainty plus Prior Equals Rational Bias: {{An}} Intuitive {{Bayesian}} Probability Weighting Function.},
  shorttitle = {Uncertainty plus Prior Equals Rational Bias},
  author = {Fennell, John and Baddeley, Roland},
  year = {2012},
  volume = {119},
  pages = {878--887},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0029346},
  journal = {Psychological Review},
  language = {en},
  number = {4}
}

@article{fox.tversky1998,
  title = {A {{Belief}}-{{Based Account}} of {{Decision Under Uncertainty}}},
  author = {Fox, Craig and Tversky, Amos},
  year = {1998},
  month = jul,
  volume = {44},
  pages = {879--895},
  doi = {10.1287/mnsc.44.7.879},
  abstract = {We develop a belief-based account of decision under uncertainty. This model predicts decisions under uncertainty from (i) judgments of probability, which are assumed to satisfy support theory; and (ii) decisions under risk, which are assumed to satisfy prospect theory. In two experiments, subjects evaluated uncertain prospects and assessed the probability of the respective events. Study 1 involved the 1995 professional basketball playoffs; Study 2 involved the movement of economic indicators in a simulated economy. The results of both studies are consistent with the belief-based account, but violate the partition inequality implied by the classical theory of decision under uncertainty.},
  file = {/Users/dmpowell/Documents/Papers/fox-tversky-1998-a belief-based account of decision under uncertainty.pdf},
  journal = {Management Science}
}

@article{franke.etal2016,
  title = {What Does the Crowd Believe? {{A}} Hierarchical Approach to Estimating Subjective Beliefs from Empirical Data},
  author = {Franke, Michael and Dablander, Fabian and Scholler, Anthea and Bennett, Erin and Degen, Judith and Tessler, Michael Henry and Kao, Justine and Goodman, Noah D},
  year = {2016},
  pages = {6},
  abstract = {People's beliefs about everyday events are both of theoretical interest in their own right and an important ingredient in model building\textemdash especially in Bayesian cognitive models of phenomena such as logical reasoning, future predictions, and language use. Here, we explore several recently used methods for measuring subjective beliefs about unidimensional contiguous properties, such as the likely price of a new watch. As a first step towards a way of assessing and comparing belief elicitation methods, we use hierarchical Bayesian modeling for inferring likely population-level beliefs as the central tendency of participants' individual-level beliefs. Three different dependent measures are considered: (i) slider ratings of (relative) likelihood of intervals of values, (ii) a give-a-number task, and (iii) choice of the more likely of two intervals of values. Our results suggest that using averaged normalized slider ratings for binned quantities is a practical and fairly good approximator of inferred population-level beliefs.},
  file = {/Users/dmpowell/Documents/Papers/Franke et al. - What does the crowd believe A hierarchical approa.pdf},
  language = {en}
}

@article{gelman.etal2014,
  title = {Understanding Predictive Information Criteria for {{Bayesian}} Models},
  author = {Gelman, Andrew and Hwang, Jessica and Vehtari, Aki},
  year = {2014},
  month = nov,
  volume = {24},
  pages = {997--1016},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-013-9416-2},
  abstract = {We review the Akaike, deviance, and Watanabe-Akaike information criteria from a Bayesian perspective, where the goal is to estimate expected out-of-sample-prediction error using a biascorrected adjustment of within-sample error. We focus on the choices involved in setting up these measures, and we compare them in three simple examples, one theoretical and two applied. The contribution of this review is to put all these information criteria into a Bayesian predictive context and to better understand, through small examples, how these methods can apply in practice.},
  file = {/Users/dmpowell/Zotero/storage/XN7K2S34/Gelman et al. - 2014 - Understanding predictive information criteria for .pdf},
  journal = {Statistics and Computing},
  language = {en},
  number = {6}
}

@book{gelman.etal2014a,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year = {2014},
  edition = {Third edition},
  publisher = {{CRC Press}},
  address = {{Boca Raton}},
  abstract = {"Preface This book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader's previous experience in probability, statistics, and linear algebra should ideally have included strong computational components. To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, beyond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods without first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book"--},
  file = {/Users/dmpowell/Zotero/storage/JQIR2DBP/Gelman et al. - Bayesian Data Analysis Third edition (with errors .pdf},
  isbn = {978-1-4398-4095-5},
  keywords = {Bayesian statistical decision theory,MATHEMATICS / Probability \& Statistics / General},
  lccn = {QA279.5 .G45 2014},
  series = {Chapman \& {{Hall}}/{{CRC}} Texts in Statistical Science}
}

@article{griffiths.tenenbaum2006,
  title = {Optimal {{Predictions}} in {{Everyday Cognition}}},
  author = {Griffiths, Thomas L. and Tenenbaum, Joshua B.},
  year = {2006},
  month = sep,
  volume = {17},
  pages = {767--773},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2006.01780.x},
  abstract = {Human perception and memory are often explained as optimal statistical inferences that are informed by accurate prior probabilities. In contrast, cognitive judgments are usually viewed as following error-prone heuristics that are insensitive to priors. We examined the optimality of human cognition in a more realistic context than typical laboratory studies, asking people to make predictions about the duration or extent of everyday phenomena such as human life spans and the box-office take of movies. Our results suggest that everyday cognitive judgments follow the same optimal statistical principles as perception and memory, and reveal a close correspondence between people's implicit probabilistic models and the statistics of the world.},
  file = {/Users/dmpowell/Documents/Papers/Griffiths and Tenenbaum - 2006 - Optimal Predictions in Everyday Cognition.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {9}
}

@article{gronau.wagenmakers2019,
  title = {Limitations of {{Bayesian Leave}}-{{One}}-{{Out Cross}}-{{Validation}} for {{Model Selection}}},
  author = {Gronau, Quentin F. and Wagenmakers, Eric-Jan},
  year = {2019},
  month = mar,
  volume = {2},
  pages = {1--11},
  issn = {2522-087X},
  doi = {10.1007/s42113-018-0011-7},
  abstract = {Cross-validation (CV) is increasingly popular as a generic method to adjudicate between mathematical models of cognition and behavior. In order to measure model generalizability, CV quantifies out-of-sample predictive performance, and the CV preference goes to the model that predicted the out-of-sample data best. The advantages of CV include theoretic simplicity and practical feasibility. Despite its prominence, however, the limitations of CV are often underappreciated. Here, we demonstrate the limitations of a particular form of CV\textemdash Bayesian leave-one-out cross-validation or LOO\textemdash with three concrete examples. In each example, a data set of infinite size is perfectly in line with the predictions of a simple model (i.e., a general law or invariance). Nevertheless, LOO shows bounded and relatively modest support for the simple model. We conclude that CV is not a panacea for model selection.},
  file = {/Users/dmpowell/Documents/Papers/gronau-wagenmakers-2019-limitations of bayesian leave-one-out cross-validation for model selection.pdf},
  journal = {Computational Brain \& Behavior},
  language = {en},
  number = {1}
}

@article{hilbert2012,
  title = {Toward a Synthesis of Cognitive Biases: {{How}} Noisy Information Processing Can Bias Human Decision Making.},
  shorttitle = {Toward a Synthesis of Cognitive Biases},
  author = {Hilbert, Martin},
  year = {2012},
  month = mar,
  volume = {138},
  pages = {211--237},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/a0025940},
  file = {/Users/dmpowell/Documents/Papers/hilbert-2012-toward a synthesis of cognitive biases.pdf},
  journal = {Psychological Bulletin},
  language = {en},
  number = {2}
}

@book{jaynes2003,
  title = {Probability {{Theory}}: {{The Logic}} of {{Science}}},
  shorttitle = {Probability {{Theory}}},
  author = {Jaynes, E. T.},
  editor = {Bretthorst, G. Larry},
  year = {2003},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UNITED KINGDOM}},
  file = {/Users/dmpowell/Zotero/storage/ZWW8M7EQ/reader.html},
  isbn = {978-1-139-14672-2},
  keywords = {Probabilities}
}

@article{jern.etal2014,
  title = {Belief Polarization Is Not Always Irrational.},
  author = {Jern, Alan and Chang, Kai-min K. and Kemp, Charles},
  year = {2014},
  volume = {121},
  pages = {206--224},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0035941},
  abstract = {Belief polarization occurs when 2 people with opposing prior beliefs both strengthen their beliefs after observing the same data. Many authors have cited belief polarization as evidence of irrational behavior. We show, however, that some instances of polarization are consistent with a normative account of belief revision. Our analysis uses Bayesian networks to characterize different kinds of relationships between hypotheses and data, and distinguishes between cases in which normative reasoners with opposing beliefs should both strengthen their beliefs, cases in which both should weaken their beliefs, and cases in which one should strengthen and the other should weaken his or her belief. We apply our analysis to several previous studies of belief polarization and present a new experiment that suggests that people tend to update their beliefs in the directions predicted by our normative account.},
  file = {/Users/dmpowell/Documents/Papers/Jern et al. - 2014 - Belief polarization is not always irrational..pdf},
  journal = {Psychological Review},
  language = {en},
  number = {2}
}

@book{kahneman2013,
  title = {Thinking, {{Fast}} and {{Slow}}},
  author = {Kahneman, Daniel},
  year = {2013},
  month = apr,
  edition = {1st edition},
  publisher = {{Farrar, Straus and Giroux}},
  address = {{New York}},
  abstract = {Major New York Times bestsellerOver two million copies soldSelected by the New York Times Book Review as one of the ten best books of 2011Selected by The Wall Street Journal as one of the best nonfiction books of 20112013 Presidential Medal of Freedom RecipientDaniel Kahneman's work with Amos Tversky is the subject of Michael Lewis's best-selling The Undoing Project: A Friendship That Changed Our MindsIn his mega bestseller, Thinking, Fast and Slow, Daniel Kahneman, world-famous psychologist and winner of the Nobel Prize in Economics, takes us on a groundbreaking tour of the mind and explains the two systems that drive the way we think. System 1 is fast, intuitive, and emotional; System 2 is slower, more deliberative, and more logical. The impact of overconfidence on corporate strategies, the difficulties of predicting what will make us happy in the future, the profound effect of cognitive biases on everything from playing the stock market to planning our next vacation\rule{1em}{1pt}each of these can be understood only by knowing how the two systems shape our judgments and decisions.Engaging the reader in a lively conversation about how we think, Kahneman reveals where we can and cannot trust our intuitions and how we can tap into the benefits of slow thinking. He offers practical and enlightening insights into how choices are made in both our business and our personal lives\rule{1em}{1pt}and how we can use different techniques to guard against the mental glitches that often get us into trouble. Topping bestseller lists for almost ten years, Thinking, Fast and Slow is a contemporary classic, an essential book that has changed the lives of millions of readers.},
  isbn = {978-0-374-53355-7},
  language = {English}
}

@article{kersten.etal2004,
  title = {Object {{Perception}} as {{Bayesian Inference}}},
  author = {Kersten, Daniel and Mamassian, Pascal and Yuille, Alan},
  year = {2004},
  month = feb,
  volume = {55},
  pages = {271--304},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev.psych.55.090902.142005},
  file = {/Users/dmpowell/Zotero/storage/A8LR4LDE/Kersten et al. - 2004 - Object Perception as Bayesian Inference.pdf},
  journal = {Annual Review of Psychology},
  language = {en},
  number = {1}
}

@book{kuhn1977,
  title = {The Essential Tension: Selected Studies in Scientific Tradition and Change},
  shorttitle = {The Essential Tension},
  author = {Kuhn, Thomas Samuel},
  year = {1977},
  publisher = {{University of Chicago press}},
  address = {{Chicago London}},
  isbn = {978-0-226-45806-9},
  langid = {english},
  lccn = {501}
}

@article{lu.etal2012,
  title = {Bayesian Analogy with Relational Transformations.},
  author = {Lu, Hongjing and Chen, Dawn and Holyoak, Keith J.},
  year = {2012},
  volume = {119},
  pages = {617--648},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0028719},
  abstract = {How can humans acquire relational representations that enable analogical inference and other forms of high-level reasoning? Using comparative relations as a model domain, we explore the possibility that bottom-up learning mechanisms applied to objects coded as feature vectors can yield representations of relations sufficient to solve analogy problems. We introduce Bayesian Analogy with Relational Transformations (BART), and apply the model to the task of learning first-order comparative relations (e.g., larger, smaller, fiercer, meeker) from a set of animal pairs. Inputs are coded by vectors of continuous-valued features, based either on human magnitude ratings, normed feature ratings (De Deyne et al., 2008), or outputs of the topics model (Griffiths, Steyvers, \& Tenenbaum, 2007). Bootstrapping from empirical priors, the model is able to induce first-order relations represented as probabilistic weight distributions, even when given positive examples only. These learned representations allow classification of novel instantiations of the relations, and yield a symbolic distance effect of the sort obtained with both humans and other primates. BART then transforms its learned weight distributions by importance-guided mapping, thereby placing distinct dimensions into correspondence. These transformed representations allow BART to reliably solve four-term analogies (e.g., larger:smaller :: fiercer:meeker), a type of reasoning that is arguably specific to humans. Our results provide a proof-of-concept that structured analogies can be solved using representations induced from unstructured feature vectors by mechanisms that operate in a largely bottom-up fashion. We discuss potential implications for algorithmic and neural models of relational thinking, as well as for the evolution of abstract thought.},
  file = {/Users/dmpowell/Documents/Papers/Lu et al. - 2012 - Bayesian analogy with relational transformations..pdf},
  journal = {Psychological Review},
  language = {en},
  number = {3}
}

@article{mellers.etal2001,
  title = {Do {{Frequency Representations Eliminate Conjunction Effects}}? {{An Exercise}} in {{Adversarial Collaboration}}},
  shorttitle = {Do {{Frequency Representations Eliminate Conjunction Effects}}?},
  author = {Mellers, Barbara and Hertwig, Ralph and Kahneman, Daniel},
  year = {2001},
  month = jul,
  volume = {12},
  pages = {269--275},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.00350},
  abstract = {The present article offers an approach to scientific debate called adversarial collaboration. The approach requires both parties to agree on empirical tests for resolving a dispute and to conduct these tests with the help of an arbiter. In dispute were Hertwig's claims that frequency formats eliminate conjunction effects and that the conjunction effects previously reported by Kahneman and Tversky occurred because some participants interpreted the word ``and'' in ``bank tellers and feminists'' as a union operator. Hertwig proposed two new conjunction phrases, ``and are'' and ``who are,'' that would eliminate the ambiguity. Kahneman disagreed with Hertwig's predictions for ``and are,'' but agreed with his predictions for ``who are.'' Mellers served as arbiter. Frequency formats by themselves did not eliminate conjunction effects with any of the phrases, but when filler items were removed, conjunction effects disappeared with Hertwig's phrases. Kahneman and Hertwig offer different interpretations of the findings. We discuss the benefits of adversarial collaboration over replies and rejoinders, and present a suggested protocol for adversarial collaboration.},
  file = {/Users/dmpowell/Zotero/storage/XBDRXE8E/Mellers et al. - 2001 - Do Frequency Representations Eliminate Conjunction.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {4}
}

@article{navarro,
  title = {Between the Devil and the Deep Blue Sea: {{Tensions}} between Scientific Judgement and Statistical Model Selection},
  author = {Navarro, Danielle J},
  pages = {12},
  abstract = {Discussions of model selection in the psychological literature typically frame the issues as a question of statistical inference, with the goal being to determine which model makes the best predictions about data. Within this setting, advocates of leave-one-out cross-validation and Bayes factors disagree on precisely which prediction problem model selection questions should aim to answer. In this comment, I discuss some of these issues from a scientific perspective. What goal does model selection serve when all models are 6 known to be systematically wrong? How might ``toy problems'' tell a misleading story? How does the scientific goal of explanation align with (or differ from) traditional statistical concerns? I do not offer answers to these questions, but hope to highlight the reasons why psychological researchers cannot avoid asking them.},
  file = {/Users/dmpowell/Zotero/storage/T98RSHYA/Navarro - Between the devil and the deep blue sea Tensions .pdf},
  language = {en}
}

@article{phan.etal2019,
  title = {Composable {{Effects}} for {{Flexible}} and {{Accelerated Probabilistic Programming}} in {{NumPyro}}},
  author = {Phan, Du and Pradhan, Neeraj and Jankowiak, Martin},
  year = {2019},
  month = dec,
  abstract = {NumPyro is a lightweight library that provides an alternate NumPy backend to the Pyro probabilistic programming language with the same modeling interface, language primitives and effect handling abstractions. Effect handlers allow Pyro's modeling API to be extended to NumPyro despite its being built atop a fundamentally different JAX-based functional backend. In this work, we demonstrate the power of composing Pyro's effect handlers with the program transformations that enable hardware acceleration, automatic differentiation, and vectorization in JAX. In particular, NumPyro provides an iterative formulation of the No-U-Turn Sampler (NUTS) that can be end-to-end JIT compiled, yielding an implementation that is much faster than existing alternatives in both the small and large dataset regimes.},
  archiveprefix = {arXiv},
  eprint = {1912.11554},
  eprinttype = {arxiv},
  file = {/Users/dmpowell/Zotero/storage/BMDN5MJD/Phan et al. - 2019 - Composable Effects for Flexible and Accelerated Pr.pdf;/Users/dmpowell/Zotero/storage/2LULHYKF/1912.html},
  journal = {arXiv:1912.11554 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Programming Languages,G.3,I.2.5,I.2.5; G.3,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{piantadosi2018,
  title = {One Parameter Is Always Enough},
  author = {Piantadosi, Steven T.},
  year = {2018},
  month = sep,
  journal = {AIP Advances},
  volume = {8},
  number = {9},
  pages = {095118},
  publisher = {{American Institute of Physics}},
  doi = {10.1063/1.5031956},
  abstract = {We construct an elementary equation f\texttheta (x) with a single real valued parameter \texttheta{} {$\in$} [0, 1] that, as \texttheta{} varies, is capable of fitting any scatter plot on any number of points to within a fixed precision. Specifically, given {$\epsilon$} {$>$} 0, we may construct f\texttheta{} so that for any collection of ordered pairs  \{( {$\mathsl{x}$} {$\mathsl{j}$} , {$\mathsl{y}$} {$\mathsl{j}$} )\} {$\mathsl{n}$} {$\mathsl{j}$}=0 \{(xj,yj)\}j=0n  with  {$\mathsl{n}$}, {$\mathsl{x}$} {$\mathsl{i}$} {$\in\mathbb{N}$} n,xi{$\in$}N  and yi {$\in$} (0, 1), there exists a \texttheta{} {$\in$} [0, 1] giving |f\texttheta (xj) - yj| {$<$} {$\epsilon$} for all j simultaneously. To achieve this, we apply results about the logistic map, an iterated map in dynamical systems theory that can be solved exactly. The existence of an equation f\texttheta{} with this property highlights that ``parameter counting'' fails as a measure of model complexity when the class of models under consideration is only slightly broad.},
  file = {/Users/dmpowell/Documents/Papers/Piantadosi-2018-One parameter is always enough.pdf}
}

@article{powell.etal2018,
  title = {Articulating Lay Theories through Graphical Models: {{A}} Study of Beliefs Surrounding Vaccination Decisions},
  author = {Powell, Derek and Weisman, Kara and Markman, Ellen M},
  year = {2018},
  pages = {6},
  abstract = {How can we leverage the cognitive science of lay theories to inform interventions aimed at correcting misconceptions and changing behaviors? Focusing on the problem of vaccine skepticism, we identified a set of 14 beliefs we hypothesized would be relevant to vaccination decisions. We developed reliable scales to measure these beliefs across a large sample of participants (n = 1130) and employed state-of-the-art graphical structure learning algorithms to uncover the relationships among these beliefs. This resulted in a graphical model describing the system of beliefs relevant to childhood vaccinations, with beliefs represented as nodes and their interconnections as directed edges. This model sheds light on how these beliefs relate to one another and can be used to predict how interventions aimed at specific beliefs will play out across the larger system. Moving forward, we hope this modeling approach will help guide the development of effective, theory-based interventions promoting childhood vaccination.},
  file = {/Users/dmpowell/Zotero/storage/B9U64XKH/Powell et al. - Articulating lay theories through graphical models.pdf},
  language = {en}
}

@article{sides.etal2002,
  title = {On the Reality of the Conjunction Fallacy},
  author = {Sides, Ashley and Osherson, Daniel and Bonini, Nicolao and Viale, Riccardo},
  year = {2002},
  month = mar,
  volume = {30},
  pages = {191--198},
  issn = {1532-5946},
  doi = {10.3758/BF03195280},
  abstract = {Attributing higher ``probability'' to a sentence of formp-and-q, relative top, is a reasoning fallacy only if (1) the wordprobability carries its modern, technical meaning and (2) the sentencep is interpreted as a conjunct of the conjunctionp-and-q. Legitimate doubts arise about both conditions in classic demonstrations of the conjunction fallacy. We used betting paradigms and unambiguously conjunctive statements to reduce these sources of ambiguity about conjunctive reasoning. Despite the precautions, conjunction fallacies were as frequent under betting instructions as under standard probability instructions.},
  file = {/Users/dmpowell/Zotero/storage/9HFIESXW/Sides et al. - 2002 - On the reality of the conjunction fallacy.pdf},
  journal = {Memory \& Cognition},
  language = {en},
  number = {2}
}

@article{smithson.etal2011,
  title = {Beta {{Regression Finite Mixture Models}} of {{Polarization}} and {{Priming}}},
  author = {Smithson, Michael and Merkle, Edgar C. and Verkuilen, Jay},
  year = {2011},
  month = dec,
  volume = {36},
  pages = {804--831},
  publisher = {{American Educational Research Association}},
  issn = {1076-9986},
  doi = {10.3102/1076998610396893},
  abstract = {This paper describes the application of finite-mixture general linear models based on the beta distribution to modeling response styles, polarization, anchoring, and priming effects in probability judgments. These models, in turn, enhance our capacity for explicitly testing models and theories regarding the aforementioned phenomena. The mixture model approach is superior in this regard to popular methods such as extremity scores, due to its incorporation of three submodels (location, dispersion, and relative composition), each of which can diagnose specific kinds of polarization and related effects. Three examples are elucidated using real data sets.},
  file = {/Users/dmpowell/Documents/Papers/smithson et al-2011-beta regression finite mixture models of polarization and priming.pdf},
  journal = {Journal of Educational and Behavioral Statistics},
  keywords = {anchoring,beta distribution,mixture model,polarization,priming},
  language = {en},
  number = {6}
}

@incollection{sober2002,
  title = {What Is the Problem of Simplicity?},
  booktitle = {Simplicity, {{Inference}} and {{Modelling}}},
  author = {Sober, Elliott},
  editor = {Zellner, Arnold and Keuzenkamp, Hugo A. and McAleer, Michael},
  year = {2002},
  month = feb,
  edition = {First},
  pages = {13--31},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511493164.002},
  isbn = {978-0-521-80361-8 978-0-511-49316-4 978-0-521-12135-4},
  file = {/Users/derekpowell/Zotero/storage/BBW9YRZR/2004 Simplicity, Inference and Modelling.pdf}
}

@article{tenenbaum.etal2011,
  title = {How to {{Grow}} a {{Mind}}: {{Statistics}}, {{Structure}}, and {{Abstraction}}},
  shorttitle = {How to {{Grow}} a {{Mind}}},
  author = {Tenenbaum, Joshua B. and Kemp, Charles and Griffiths, Thomas L. and Goodman, Noah D.},
  year = {2011},
  month = mar,
  volume = {331},
  pages = {1279--1285},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1192788},
  abstract = {In coming to understand the world\textemdash in learning concepts, acquiring language, and grasping causal relations\textemdash our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?},
  chapter = {Review},
  copyright = {Copyright \textcopyright{} 2011, American Association for the Advancement of Science},
  file = {/Users/dmpowell/Zotero/storage/BSQ6ZNW7/Tenenbaum et al. - 2011 - How to Grow a Mind Statistics, Structure, and Abs.pdf;/Users/dmpowell/Zotero/storage/E2HRQ9H6/1279.html},
  journal = {Science},
  language = {en},
  number = {6022},
  pmid = {21393536}
}

@article{tentori.etal2012,
  title = {On the {{Determinants}} of the {{Conjunction Fallacy}}: {{Probability Versus Inductive Confirmation}}},
  shorttitle = {On the {{Determinants}} of the {{Conjunction Fallacy}}},
  author = {Tentori, Katya and Crupi, Vincenzo and Russo, Selena},
  year = {2012},
  month = jul,
  volume = {142},
  doi = {10.1037/a0028770},
  abstract = {Major recent interpretations of the conjunction fallacy postulate that people assess the probability of a conjunction according to (non-normative) averaging rules as applied to the constituents' probabilities or represent the conjunction fallacy as an effect of random error in the judgment process. In the present contribution, we contrast such accounts with a different reading of the phenomenon based on the notion of inductive confirmation as defined by contemporary Bayesian theorists. Averaging rule hypotheses along with the random error model and many other existing proposals are shown to all imply that conjunction fallacy rates would rise as the perceived probability of the added conjunct does. By contrast, our account predicts that the conjunction fallacy depends on the added conjunct being perceived as inductively confirmed. Four studies are reported in which the judged probability versus confirmation of the added conjunct have been systematically manipulated and dissociated. The results consistently favor a confirmation-theoretic account of the conjunction fallacy against competing views. Our proposal is also discussed in connection with related issues in the study of human inductive reasoning. (PsycINFO Database Record (c) 2012 APA, all rights reserved).},
  file = {/Users/dmpowell/Documents/Papers/tentori et al-2012-on the determinants of the conjunction fallacy.pdf},
  journal = {Journal of experimental psychology. General}
}

@article{tversky.kahneman1983,
  title = {Extensional {{Versus Intuitive Reasoning}}: {{The Conjunction Fallacy}} in {{Probability Judgment}}},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1983},
  volume = {90},
  pages = {23},
  file = {/Users/dmpowell/Zotero/storage/2L6TI4PY/Tversky and Kahneman - Extensional Versus Intuitive Reasoning The Conjun.pdf},
  journal = {Psychological Review},
  language = {en},
  number = {4}
}

@article{tversky.koehler1994,
  title = {Support Theory: {{A}} Nonextensional Representation of Subjective Probability},
  shorttitle = {Support Theory},
  author = {Tversky, Amos and Koehler, Derek J.},
  year = {1994},
  month = oct,
  volume = {101},
  pages = {547--567},
  publisher = {{American Psychological Association}},
  address = {{Washington, US}},
  issn = {0033-295X},
  doi = {http://dx.doi.org.ezproxy1.lib.asu.edu/10.1037/0033-295X.101.4.547},
  abstract = {Presents a new theory of subjective probability according to which different descriptions of the same event can give rise to different judgments. The experimental evidence confirms the major predictions of the theory. First, judged probability increases by unpacking the focal hypothesis and decreases by unpacking the alternative hypothesis. Second, judged probabilities are complementary in the binary case and subadditive in the general case, contrary to both classical and revisionist models of belief. Third, subadditivity is more pronounced for probability judgments than for frequency judgments and is enhanced by compatible evidence. The theory provides a unified treatment of a wide range of empirical findings. It is extended to ordinal judgments and to the assessment of upper and lower probabilities. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  annotation = {(US)},
  copyright = {\textcopyright{} 1994, American Psychological Association},
  file = {/Users/dmpowell/Zotero/storage/M36T2AE5/Tversky and Koehler - 1994 - Support theory A nonextensional representation of.pdf},
  journal = {Psychological Review},
  keywords = {Probability Judgment (major),Theories},
  language = {English},
  number = {4}
}

@article{vehtari.etal2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  volume = {27},
  pages = {1413--1432},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparing of predictive errors between two models. We implement the computations in an R package called 'loo' and demonstrate using models fit with the Bayesian inference package Stan.},
  archiveprefix = {arXiv},
  eprint = {1507.04544},
  eprinttype = {arxiv},
  file = {/Users/dmpowell/Documents/Papers/vehtari et al-2017-practical bayesian model evaluation using leave-one-out cross-validation and.pdf;/Users/dmpowell/Zotero/storage/3KSVW8VW/1507.html},
  journal = {Statistics and Computing},
  keywords = {Statistics - Computation,Statistics - Methodology},
  number = {5}
}

@article{vehtari.etal2019,
  title = {Limitations of ``{{Limitations}} of {{Bayesian Leave}}-One-out {{Cross}}-{{Validation}} for {{Model Selection}}''},
  author = {Vehtari, Aki and Simpson, Daniel P. and Yao, Yuling and Gelman, Andrew},
  year = {2019},
  month = mar,
  volume = {2},
  pages = {22--27},
  issn = {2522-087X},
  doi = {10.1007/s42113-018-0020-6},
  abstract = {In an earlier article in this journal, Gronau and Wagenmakers (2018) discuss some problems with leave-one-out cross-validation (LOO) for Bayesian model selection. However, the variant of LOO that Gronau and Wagenmakers discuss is at odds with a long literature on how to use LOO well. In this discussion, we discuss the use of LOO in practical data analysis, from the perspective that we need to abandon the idea that there is a device that will produce a single-number decision rule.},
  file = {/Users/dmpowell/Documents/Papers/vehtari et al-2019-limitations of “limitations of bayesian leave-one-out cross-validation for.pdf},
  journal = {Computational Brain \& Behavior},
  language = {en},
  number = {1}
}

@article{wright.bray2003,
  title = {A {{Mixture Model}} for {{Rounded Data}}},
  author = {Wright, David E. and Bray, Isabelle},
  year = {2003},
  volume = {52},
  pages = {3--13},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0039-0526},
  abstract = {The paper focuses on the problem of data heaping that arises when measurements are recorded to varying degrees of precision. The work is motivated by an application in foetal medicine where measurements obtained from ultrasound images are rounded to varying numbers of decimal places causing heaping at integer values. We demonstrate the dangers of ignoring heaping before presenting a case-study of the ultrasound measurements. A mixture model, in which the different components represent different levels of rounding, is used for the heaping process. We illustrate a range of graphical posterior predictive checks to assess the fit of the model and we explore some extensions of the model. We adopt a Bayesian approach implemented by using the Gibbs sampler.},
  file = {/Users/dmpowell/Documents/Papers/Wright_Bray-2003-A Mixture Model for Rounded Data.pdf},
  journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
  number = {1}
}

@article{xu.tenenbaum2007,
  title = {Word Learning as {{Bayesian}} Inference.},
  author = {Xu, Fei and Tenenbaum, Joshua B.},
  year = {2007},
  volume = {114},
  pages = {245--272},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.114.2.245},
  abstract = {The authors present a Bayesian framework for understanding how adults and children learn the meanings of words. The theory explains how learners can generalize meaningfully from just one or a few positive examples of a novel word's referents, by making rational inductive inferences that integrate prior knowledge about plausible word meanings with the statistical structure of the observed examples. The theory addresses shortcomings of the two best known approaches to modeling word learning, based on deductive hypothesis elimination and associative learning. Three experiments with adults and children test the Bayesian account's predictions in the context of learning words for object categories at multiple levels of a taxonomic hierarchy. Results provide strong support for the Bayesian account over competing accounts, in terms of both quantitative model fits and the ability to explain important qualitative phenomena. Several extensions of the basic theory are discussed, illustrating the broader potential for Bayesian models of word learning.},
  file = {/Users/dmpowell/Documents/Papers/Xu and Tenenbaum - 2007 - Word learning as Bayesian inference..pdf},
  journal = {Psychological Review},
  language = {en},
  number = {2}
}

@article{zhu.etal2020,
  title = {The {{Bayesian}} Sampler: {{Generic Bayesian}} Inference Causes Incoherence in Human Probability Judgments.},
  shorttitle = {The {{Bayesian}} Sampler},
  author = {Zhu, Jian-Qiao and Sanborn, Adam N. and Chater, Nick},
  year = {2020},
  month = oct,
  volume = {127},
  pages = {719--748},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/rev0000190},
  abstract = {Human probability judgments are systematically biased, in apparent tension with Bayesian models of cognition. But perhaps the brain does not represent probabilities explicitly, but approximates probabilistic calculations through a process of sampling, as used in computational probabilistic models in statistics. Na\"ive probability estimates can be obtained by calculating the relative frequency of an event within a sample, but these estimates tend to be extreme when the sample size is small. We propose instead that people use a generic prior to improve the accuracy of their probability estimates based on samples, and we call this model the Bayesian sampler. The Bayesian sampler trades off the coherence of probabilistic judgments for improved accuracy, and provides a single framework for explaining phenomena associated with diverse biases and heuristics such as conservatism and the conjunction fallacy. The approach turns out to provide a rational reinterpretation of ``noise'' in an important recent model of probability judgment, the probability theory plus noise model (Costello \& Watts, 2014, 2016a, 2017; Costello \& Watts, 2019; Costello, Watts, \& Fisher, 2018), making equivalent average predictions for simple events, conjunctions, and disjunctions. The Bayesian sampler does, however, make distinct predictions for conditional probabilities and distributions of probability estimates. We show in 2 new experiments that this model better captures these mean judgments both qualitatively and quantitatively; which model best fits individual distributions of responses depends on the assumed size of the cognitive sample.},
  file = {/Users/dmpowell/Documents/Papers/Zhu et al. - 2020 - The Bayesian sampler Generic Bayesian inference c.pdf},
  journal = {Psychological Review},
  language = {en},
  number = {5}
}


@article{papaspiliopoulos.etal2007,
  title = {A {{General Framework}} for the {{Parametrization}} of {{Hierarchical Models}}},
  author = {Papaspiliopoulos, Omiros and Roberts, Gareth O. and Sk{\"o}ld, Martin},
  year = {2007},
  month = feb,
  volume = {22},
  issn = {0883-4237},
  doi = {10.1214/088342307000000014},
  abstract = {In this paper, we describe centering and noncentering methodology as complementary techniques for use in parametrization of broad classes of hierarchical models, with a view to the construction of effective MCMC algorithms for exploring posterior distributions from these models. We give a clear qualitative understanding as to when centering and noncentering work well, and introduce theory concerning the convergence time complexity of Gibbs samplers using centered and noncentered parametrizations. We give general recipes for the construction of noncentered parametrizations, including an auxiliary variable technique called the state-space expansion technique. We also describe partially noncentered methods, and demonstrate their use in constructing robust Gibbs sampler algorithms whose convergence properties are not overly sensitive to the data.},
  file = {/Users/dmpowell/Zotero/storage/QJBWCW7V/Papaspiliopoulos et al. - 2007 - A General Framework for the Parametrization of Hie.pdf},
  journal = {Statistical Science},
  language = {en},
  number = {1}
}

@article{sivula.etal2020,
  title = {Uncertainty in {{Bayesian Leave}}-{{One}}-{{Out Cross}}-{{Validation Based Model Comparison}}},
  author = {Sivula, Tuomas and Magnusson, M{\aa}ns and Vehtari, Aki},
  year = {2020},
  month = oct,
  journal = {arXiv:2008.10296 [stat]},
  eprint = {2008.10296},
  eprinttype = {arxiv},
  primaryclass = {stat},
  abstract = {Leave-one-out cross-validation (LOO-CV) is a popular method for comparing Bayesian models based on their estimated predictive performance on new, unseen, data. Estimating the uncertainty of the resulting LOO-CV estimate is a complex task and it is known that the commonly used standard error estimate is often too small. We analyse the frequency properties of the LOO-CV estimator and study the uncertainty related to it. We provide new results of the properties of the uncertainty both theoretically and empirically and discuss the challenges of estimating it. We show that problematic cases include: comparing models with similar predictions, misspecified models, and small data. In these cases, there is a weak connection in the skewness of the sampling distribution and the distribution of the error of the LOO-CV estimator. We show that it is possible that the problematic skewness of the error distribution, which occurs when the models make similar predictions, does not fade away when the data size grows to infinity in certain situations.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {/Users/dmpowell/Documents/Papers/sivula et al-2020-uncertainty in bayesian leave-one-out cross-validation based model comparison.pdf;/Users/dmpowell/Zotero/storage/N3ZY46NJ/2008.html}
}


@article{zhang.etal2020,
	title = {The bounded rationality of probability distortion},
	volume = {117},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1922401117},
	doi = {10.1073/pnas.1922401117},
	abstract = {Significance
            People distort probability in decision under risk and many other tasks. These distortions can be large, leading us to make markedly suboptimal decisions. There is no agreement on why we distort probability. Distortion changes systematically with task, hinting that distortions are dynamic compensations for some intrinsic “bound” on working memory. We first develop a model of the bound and compensation process and then report an experiment showing that the model accounts for individual human performance in decision under risk and relative frequency judgments. Last, we show that the particular compensation in each experimental condition serves to maximize the mutual information between objective decision variables and their internal representations. We distort probability to compensate for our own perceptual and cognitive limitations.
          ,
            In decision making under risk (DMR) participants’ choices are based on probability values systematically different from those that are objectively correct. Similar systematic distortions are found in tasks involving relative frequency judgments (JRF). These distortions limit performance in a wide variety of tasks and an evident question is, Why do we systematically fail in our use of probability and relative frequency information? We propose a bounded log-odds model (BLO) of probability and relative frequency distortion based on three assumptions: 1) log-odds: probability and relative frequency are mapped to an internal log-odds scale, 2) boundedness: the range of representations of probability and relative frequency are bounded and the bounds change dynamically with task, and 3) variance compensation: the mapping compensates in part for uncertainty in probability and relative frequency values. We compared human performance in both DMR and JRF tasks to the predictions of the BLO model as well as 11 alternative models, each missing one or more of the underlying BLO assumptions (factorial model comparison). The BLO model and its assumptions proved to be superior to any of the alternatives. In a separate analysis, we found that BLO accounts for individual participants’ data better than any previous model in the DMR literature. We also found that, subject to the boundedness limitation, participants’ choice of distortion approximately maximized the mutual information between objective task-relevant values and internal values, a form of bounded rationality.},
	language = {en},
	number = {36},
	urldate = {2022-03-07},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Zhang, Hang and Ren, Xiangjuan and Maloney, Laurence T.},
	month = sep,
	year = {2020},
	pages = {22024--22034},
	file = {Zhang et al-2020-The bounded rationality of probability distortion.pdf:/Users/derekpowell/Documents/Papers/Zhang et al-2020-The bounded rationality of probability distortion.pdf:application/pdf},
}

@article{zhang.maloney2012,
	title = {Ubiquitous {Log} {Odds}: {A} {Common} {Representation} of {Probability} and {Frequency} {Distortion} in {Perception}, {Action}, and {Cognition}},
	volume = {6},
	issn = {1662-4548},
	shorttitle = {Ubiquitous {Log} {Odds}},
	url = {http://journal.frontiersin.org/article/10.3389/fnins.2012.00001/abstract},
	doi = {10.3389/fnins.2012.00001},
	urldate = {2022-03-07},
	journal = {Frontiers in Neuroscience},
	author = {Zhang, Hang and Maloney, Laurence T.},
	year = {2012},
	file = {Zhang_Maloney-2012-Ubiquitous Log Odds.pdf:/Users/derekpowell/Documents/Papers/Zhang_Maloney-2012-Ubiquitous Log Odds.pdf:application/pdf},
}


@misc{sundh.etal2021,
	title = {The mean-variance signature of {Bayesian} probability judgment},
	url = {https://psyarxiv.com/yuhaz/},
	doi = {10.31234/osf.io/yuhaz},
	abstract = {Human probability judgments are variable and subject to systematic biases. Sampling-based accounts of probability judgment have successfully explained such idiosyncrasies by assuming that people remember or simulate instances of events and base their judgments on sampled frequencies. Biases have been explained either by noise corrupting sample accumulation (the Probability Theory + Noise account), or as a Bayesian adjustment to the uncertainty implicit in small samples (the Bayesian sampler). While these two accounts closely mimic one another, here we show that they can be distinguished by a novel linear regression method that relates the variance of repeated judgments to their means. First, the efficacy of the method is confirmed by model recovery, and it more accurately recovers parameters than computationally complex methods. Second, the method is applied to both existing and new probability judgment data, which confirm that judgments are based on a small number of samples that are adjusted by a prior, as predicted by the Bayesian sampler.},
	language = {en-us},
	urldate = {2022-07-12},
	publisher = {PsyArXiv},
	author = {Sundh, Joakim and Zhu, Jianqiao and Chater, Nick and Sanborn, Adam},
	month = jul,
	year = {2021},
	keywords = {Social and Behavioral Sciences, Bayes, Cognitive Psychology, Judgment and Decision Making, bias, noise, probability, sampling},
	file = {Sundh et al-2021-The mean-variance signature of Bayesian probability judgment.pdf:/Users/derekpowell/Zotero/storage/EFQY4HMG/Sundh et al-2021-The mean-variance signature of Bayesian probability judgment.pdf:application/pdf},
}

@misc{zhu.etal2021,
	title = {The {Autocorrelated} {Bayesian} {Sampler}: {A} {Rational} {Process} for {Probability} {Judgments}, {Estimates}, {Confidence} {Intervals}, {Choices}, {Confidence} {Judgments}, and {Response} {Times}},
	shorttitle = {The {Autocorrelated} {Bayesian} {Sampler}},
	url = {https://psyarxiv.com/3qxf7/},
	doi = {10.31234/osf.io/3qxf7},
	abstract = {Normative models of decision-making optimally transform noisy (sensory) information into categorical decisions, but qualitatively mismatch human behavior. Leading computational models of behavior achieve high empirical corroboration by adding task-specific assumptions, deviating from normative principles. In response, we offer a Bayesian approach that implicitly produces a posterior distribution of possible answers (hypotheses) in response to sensory information. But we assume that the brain has no direct access to this posterior, but can only sample hypotheses according to their posterior probabilities. In this sense, we argue that the problem of normative concern in decision-making is integrating stochastic hypotheses, rather than stochastic sensory information, to make categorical decisions. This implies that human response variability arises from posterior sampling rather than sensory noise. Because human hypothesis generation is serially correlated, hypothesis samples will be autocorrelated. Guided by this new problem formulation, we develop a new normatively justified process, the Autocorrelated Bayesian Sampler (ABS), which grounds autocorrelated hypothesis generation in a sophisticated sampling algorithm. The ABS qualitatively explains many empirical effects of probability judgments, estimates, confidence intervals, choice, confidence judgments, response times, and their relationships. Our analysis demonstrates the unifying power of a perspective shift in the exploration of normative models. It also exemplifies the idea that the brain, while fundamentally Bayesian, operates using samples not probabilities, and that variability in human behavior may primarily reflect computational rather than sensory noise.},
	language = {en-us},
	urldate = {2022-07-12},
	publisher = {PsyArXiv},
	author = {Zhu, Jian-Qiao and Sundh, Joakim and Spicer, Jake and Chater, Nick and Sanborn, Adam},
	month = feb,
	year = {2021},
	keywords = {Social and Behavioral Sciences, Cognitive Psychology, Judgment and Decision Making, and Heuristics, Biases, Framing},
	file = {Zhu et al-2021-The Autocorrelated Bayesian Sampler.pdf:/Users/derekpowell/Zotero/storage/3PEKX7XQ/Zhu et al-2021-The Autocorrelated Bayesian Sampler.pdf:application/pdf},
}


@inproceedings{lieder.etal2012,
	title = {Burn-in, bias, and the rationality of anchoring},
	volume = {25},
	url = {https://proceedings.neurips.cc/paper/2012/file/81e5f81db77c596492e6f1a5a792ed53-Paper.pdf},
	booktitle = {Advances in neural information processing systems},
	publisher = {Curran Associates, Inc.},
	author = {Lieder, Falk and Griffiths, Tom and Goodman, Noah},
	editor = {Pereira, F. and Burges, C.J. and Bottou, L. and Weinberger, K.Q.},
	year = {2012},
	file = {Lieder - Burn-in, bias, and the rationality of anchoring.pdf:/Users/derekpowell/Zotero/storage/LXBXGWY7/Lieder - Burn-in, bias, and the rationality of anchoring.pdf:application/pdf},
}



@article{sanborn.chater2016,
	title = {Bayesian {Brains} without {Probabilities}},
	volume = {20},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661316301565},
	doi = {10.1016/j.tics.2016.10.003},
	abstract = {Bayesian explanations have swept through cognitive science over the past two decades, from intuitive physics and causal learning, to perception, motor control and language. Yet people flounder with even the simplest probability questions. What explains this apparent paradox? How can a supposedly Bayesian brain reason so poorly with probabilities? In this paper, we propose a direct and perhaps unexpected answer: that Bayesian brains need not represent or calculate probabilities at all and are, indeed, poorly adapted to do so. Instead, the brain is a Bayesian sampler. Only with infinite samples does a Bayesian sampler conform to the laws of probability; with finite samples it systematically generates classic probabilistic reasoning errors, including the unpacking effect, base-rate neglect, and the conjunction fallacy.},
	language = {en},
	number = {12},
	urldate = {2022-09-09},
	journal = {Trends in Cognitive Sciences},
	author = {Sanborn, Adam N. and Chater, Nick},
	month = dec,
	year = {2016},
	keywords = {sampling, Bayesian models of cognition, reasoning biases},
	pages = {883--893},
	file = {sanborn-chater-2016-bayesian brains without probabilities.pdf:/Users/derekpowell/Documents/Papers/sanborn-chater-2016-bayesian brains without probabilities.pdf:application/pdf;ScienceDirect Snapshot:/Users/derekpowell/Zotero/storage/T6LJJVTY/S1364661316301565.html:text/html},
}


@inproceedings{kucukelbir.etal2015,
	title = {Automatic {Variational} {Inference} in {Stan}},
	volume = {28},
	url = {https://proceedings.neurips.cc/paper/2015/hash/352fe25daf686bdb4edca223c921acea-Abstract.html},
	abstract = {Variational inference is a scalable technique for approximate Bayesian inference.  Deriving variational inference algorithms requires tedious model-specific calculations; this makes it difficult for non-experts to use.  We propose an automatic variational inference algorithm, automatic differentiation variational inference (ADVI); we implement it in Stan (code available), a probabilistic programming system.  In ADVI the user provides a Bayesian model and a dataset, nothing else.  We make no conjugacy assumptions and support a broad class of models. The algorithm automatically determines an appropriate variational family and optimizes the variational objective. We compare ADVI to MCMC sampling across hierarchical generalized linear models, nonconjugate matrix factorization, and a mixture model. We train the mixture model on a quarter million images.  With ADVI we can use variational inference on any model we write in Stan.},
	urldate = {2022-08-30},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Kucukelbir, Alp and Ranganath, Rajesh and Gelman, Andrew and Blei, David},
	year = {2015},
	file = {Kucukelbir et al-2015-Automatic Variational Inference in Stan.pdf:/Users/derekpowell/Zotero/storage/FJ3EH7AW/Kucukelbir et al-2015-Automatic Variational Inference in Stan.pdf:application/pdf},
}


@article{costello.watts2018,
	title = {Invariants in probabilistic reasoning},
	volume = {100},
	issn = {00100285},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028517302013},
	doi = {10.1016/j.cogpsych.2017.11.003},
	abstract = {Recent research has identiﬁed three invariants or identities that appear to hold in people’s probabilistic reasoning: the QQ identity, the addition law identity, and the Bayes rule identity (Costello and Watts, 2014, 2016a, Fisher and Wolfe, 2014, Wang and Busemeyer, 2013, Wang et al., 2014). Each of these identities represent speciﬁc agreement with the requirements of normative probability theory; strikingly, these identities seem to hold in people’s judgements despite the presence of strong and systematic biases against the requirements of normative probability theory in those very same judgements. These results suggest that the systematic biases seen in people’s probabilistic reasoning follow mathematical rules: for these particular identities, these rules cause an overall cancellation of biases and so produce agreement with normative requirements. We assess two competing mathematical models of probabilistic reasoning (the ‘probability theory plus noise’ model and the ‘quantum probability’ model) in terms of their ability to account for this pattern of systematic biases and invariant identities.},
	language = {en},
	urldate = {2021-01-20},
	journal = {Cognitive Psychology},
	author = {Costello, Fintan and Watts, Paul},
	month = feb,
	year = {2018},
	pages = {1--16},
	file = {Costello and Watts - 2018 - Invariants in probabilistic reasoning.pdf:/Users/derekpowell/Zotero/storage/LDW7AFFB/Costello and Watts - 2018 - Invariants in probabilistic reasoning.pdf:application/pdf},
}


@article{howe.costello2020,
	title = {Random variation and systematic biases in probability estimation},
	volume = {123},
	issn = {00100285},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028520300359},
	doi = {10.1016/j.cogpsych.2020.101306},
	abstract = {A number of recent theories have suggested that the various systematic biases and fallacies seen in people’s probabilistic reasoning may arise purely as a consequence of random variation in the rea­ soning process. The underlying argument, in these theories, is that random variation has systematic regressive effects, so producing the observed patterns of bias. These theories typically take this random variation as a given, and assume that the degree of random variation in probabilistic rea­ soning is sufficiently large to account for observed patterns of fallacy and bias; there has been very little research directly examining the character of random variation in people’s probabilistic judge­ ment. We describe 4 experiments investigating the degree, level, and characteristic properties of random variation in people’s probability judgement. We show that the degree of variance is easily large enough to account for the occurrence of two central fallacies in probabilistic reasoning (the conjunction fallacy and the disjunction fallacy), and that level of variance is a reliable predictor of the occurrence of these fallacies. We also show that random variance in people’s probabilistic judgement follows a particular mathematical model from frequentist probability theory: the binomial proportion distribution. This result supports a model in which people reason about probabilities in a way that follows frequentist probability theory but is subject to random variation or noise.},
	language = {en},
	urldate = {2022-09-09},
	journal = {Cognitive Psychology},
	author = {Howe, Rita and Costello, Fintan},
	month = dec,
	year = {2020},
	pages = {101306},
	file = {Howe and Costello - 2020 - Random variation and systematic biases in probabil.pdf:/Users/derekpowell/Zotero/storage/P2VP5MLY/Howe and Costello - 2020 - Random variation and systematic biases in probabil.pdf:application/pdf},
}


@incollection{edwards1968,
	address = {New York},
	title = {Conservatism in {Human} {Information} {Processing}},
	booktitle = {Formal representation of human judgment},
	publisher = {Wiley},
	author = {Edwards, Ward},
	editor = {Kleinmuntz, B.},
	year = {1968},
	pages = {17--52},
}


@inproceedings{gershman.goodman2016,
	title = {Amortized {Inference} in {Probabilistic} {Reasoning}},
	abstract = {Recent studies of probabilistic reasoning have postulated general-purpose inference algorithms that can be used to answer arbitrary queries. These algorithms are memoryless, in the sense that each query is processed independently, without reuse of earlier computation. We argue that the brain operates in the setting of amortized inference, where numerous related queries must be answered (e.g., recognizing a scene from multiple viewpoints); in this setting, memoryless algorithms can be computationally wasteful. We propose a simple form of ﬂexible reuse, according to which shared inferences are cached and composed together to answer new queries. We present experimental evidence that humans exploit this form of reuse: the answer to a complex query can be systematically predicted from a person’s response to a simpler query if the simpler query was presented ﬁrst and entails a sub-inference (i.e., a sub-component of the more complex query). People are also faster at answering a complex query when it is preceded by a sub-inference. Our results suggest that the astonishing efﬁciency of human probabilistic reasoning may be supported by interactions between inference and memory.},
	language = {en},
	author = {Gershman, Samuel J and Goodman, Noah D},
	year = {2016},
	pages = {7},
	file = {Gershman - Amortized Inference in Probabilistic Reasoning.pdf:/Users/derekpowell/Zotero/storage/C8S3VUG2/Gershman - Amortized Inference in Probabilistic Reasoning.pdf:application/pdf},
}


@article{erev.etal1994,
	title = {Simultaneous over- and underconfidence: {The} role of error in judgment processes},
	volume = {101},
	copyright = {© 1994, American Psychological Association},
	issn = {0033-295X},
	shorttitle = {Simultaneous over- and underconfidence},
	url = {https://www.proquest.com/docview/614330855/abstract/28417D7DC114A75PQ/1},
	doi = {http://dx.doi.org/10.1037/0033-295X.101.3.519},
	abstract = {Two empirical judgment phenomena appear to contradict each other. In the revision-of-opinion literature, subjective probability (SP) judgments have been analyzed as a function of objective probability (OP) and generally have been found to be conservative, that is, to represent underconfidence. In the calibration literature, analyses of OP (operationalized as relative frequency correct) as a function of SP have led to the opposite conclusion, that judgment is generally overconfident. Reanalysis of 3 studies shows that both results can be obtained from the same set of data, depending on the method of analysis. The simultaneous effects are then generated and factors influencing them are explored by means of a model that instantiates a very general theory of how SP estimates arise from true judgments perturbed by random error. Theoretical and practical implications of the work are discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	language = {English},
	number = {3},
	urldate = {2022-01-30},
	journal = {Psychological Review},
	author = {Erev, Ido and Wallsten, Thomas S. and Budescu, David V.},
	month = jul,
	year = {1994},
	note = {Num Pages: 519-527
Place: Washington, US
Publisher: American Psychological Association
(US)},
	keywords = {Errors (major), Judgment (major), Probability Judgment, Uncertainty (major)},
	pages = {519--527},
	file = {Erev et al-1994-Simultaneous over- and underconfidence.pdf:/Users/derekpowell/Zotero/storage/M6L629CX/Erev et al-1994-Simultaneous over- and underconfidence.pdf:application/pdf},
}



@inproceedings{powell2022,
	title = {A descriptive bayesian account of optimism in belief revision},
	booktitle = {Proceedings of the 42nd {Annual} {Conference} of the {Cognitive} {Science} {Society}},
	author = {Powell, Derek},
	editor = {Jennifer, Culbertson and Perfors, Andrew and Rabagliati, Hugh and Ramenzoni, Veronica},
	year = {2022},
}



@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2021},
  url = {https://www.R-project.org/},
}
@Manual{R-papaja,
  author = {Frederik Aust and Marius Barth},
  title = {{papaja}: {Create} {APA} manuscripts with {R Markdown}},
  year = {2020},
  note = {R package version 0.1.0.9997},
  url = {https://github.com/crsh/papaja},
}

@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller},
  year = {2021},
  note = {https://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr},
}
@Manual{R-forcats,
  title = {forcats: Tools for Working with Categorical Variables (Factors)},
  author = {Hadley Wickham},
  year = {2021},
  note = {https://forcats.tidyverse.org,
https://github.com/tidyverse/forcats},
}
@Book{R-ggplot2,
  author = {Hadley Wickham},
  title = {ggplot2: Elegant Graphics for Data Analysis},
  publisher = {Springer-Verlag New York},
  year = {2016},
  isbn = {978-3-319-24277-4},
  url = {https://ggplot2.tidyverse.org},
}
@Manual{R-kableExtra,
  title = {kableExtra: Construct Complex Table with 'kable' and Pipe Syntax},
  author = {Hao Zhu},
  year = {2021},
  note = {http://haozhu233.github.io/kableExtra/,
https://github.com/haozhu233/kableExtra},
}
@Manual{R-purrr,
  title = {purrr: Functional Programming Tools},
  author = {Lionel Henry and Hadley Wickham},
  year = {2020},
  note = {http://purrr.tidyverse.org, https://github.com/tidyverse/purrr},
}
@Manual{R-readr,
  title = {readr: Read Rectangular Text Data},
  author = {Hadley Wickham and Jim Hester},
  year = {2021},
  note = {https://readr.tidyverse.org, https://github.com/tidyverse/readr},
}
@Manual{R-stringr,
  title = {stringr: Simple, Consistent Wrappers for Common String Operations},
  author = {Hadley Wickham},
  year = {2019},
  note = {http://stringr.tidyverse.org, https://github.com/tidyverse/stringr},
}
@Manual{R-tibble,
  title = {tibble: Simple Data Frames},
  author = {Kirill Müller and Hadley Wickham},
  year = {2021},
  note = {https://tibble.tidyverse.org/, https://github.com/tidyverse/tibble},
}
@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham},
  year = {2021},
  note = {https://tidyr.tidyverse.org, https://github.com/tidyverse/tidyr},
}
@Article{R-tidyverse,
  title = {Welcome to the {tidyverse}},
  author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
  year = {2019},
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {43},
  pages = {1686},
  doi = {10.21105/joss.01686},
}
@Manual{R-tinylabels,
  title = {{tinylabels}: Lightweight Variable Labels},
  author = {Marius Barth},
  year = {2022},
  note = {R package version 0.2.3},
  url = {https://cran.r-project.org/package=tinylabels},
}
